1、ELMo
传统的词向量是上下文无关的，也就是在不同的语境中，每一个词都有相同的向量。这样的词向量无法对一词多义进行建模。ELMo该模型的核心思想是利用双向语言模型，根据当前输入得到上下文依赖的词表示（同一个词在不同的上下文中有不同的向量表示）


